# --- LLM Provider: Ollama/llama.cpp OR Google Gemini ---
# If GEMINI_API_KEY is set, Gemini is used. Otherwise Ollama/llama.cpp is used.

# --- Google Gemini (AI on Cloud) ---
# Get a free API key at https://aistudio.google.com/apikey
# GEMINI_API_KEY=your_key_here
# GEMINI_MODEL=gemini-2.5-flash
# For smarter analysis use: gemini-2.5-pro
# GEMINI_BETA=true   # Use v1beta (newer models like gemini-3). Omit or false = v1 (stable)
# GEMINI_TEMPERATURE=0.2

# --- Ollama / llama.cpp (OpenAI-compatible API, local) ---
# Base URL of the server (llama.cpp, Ollama, etc.)
# Ollama default: http://localhost:11434
# llama.cpp default: http://localhost:8080
# LLAMA_SERVER_URL=http://localhost:8080
LLAMA_SERVER_URL=http://localhost:11434
# Model name (must match a model available on your server)
OLLAMA_MODEL=llama

# Request timeout in seconds
LLM_TIMEOUT=120

# Max tokens for the model response (Gemini may need 2048+ for full JSON)
LLM_MAX_TOKENS=2048

# Sampling temperature (0.0 = deterministic, higher = more random)
LLM_TEMPERATURE=0.2

# --- Paths ---
# Directory where run summaries are saved (relative to ocr dir or absolute)
# INVOICES_SUMMARY_DIR=invoices_summary

# Optional: path to system prompt file (relative to ocr dir or absolute)
# PROMPT_FILE=prompt.txt

# --- OCR (scanned PDFs) ---
# Directory to save extracted text (digital + OCR). Set empty to disable.
OCR_OUTPUT_DIR=ocr_output

# Directory for scanned-only PDFs: files here always use OCR (300 DPI). Omit to disable.
# INVOICES_OCR_DIR=invoices_scanned

# DPI when rendering PDF pages for OCR (fallback mode)
OCR_DPI=200

# DPI when forcing OCR (INVOICES_OCR_DIR or --force-ocr)
# OCR_DPI_FORCED=300

# Min characters per page below which OCR fallback is used
MIN_TEXT_PER_PAGE=50

# Tesseract config (--psm 6 = uniform block of text, good for invoices)
# OCR_CONFIG=--psm 6
